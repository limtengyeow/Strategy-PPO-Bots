{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119de28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Notebook directory: /workspace/Strategy-PPO-Bots/notebooks\n",
      "✅ Project root set to: /workspace/Strategy-PPO-Bots\n"
     ]
    }
   ],
   "source": [
    "## Set-up Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set project root (assumes notebook is in 'notebooks/' and project is one level up)\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Add root to Python path for absolute imports like `env.trading_env`\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "print(\"📁 Notebook directory:\", notebook_dir)\n",
    "print(\"✅ Project root set to:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98aa58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Strategy-PPO-Bots\n"
     ]
    }
   ],
   "source": [
    "## Check to ensure in the right directory\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af88a9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (25.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## Upgrade pip\n",
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8cbfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3 (from -r requirements.txt (line 1))\n",
      "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting gym==0.25.2 (from -r requirements.txt (line 2))\n",
      "  Downloading gym-0.25.2.tar.gz (734 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.5/734.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.10.3)\n",
      "Collecting tensorboard (from -r requirements.txt (line 6))\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting cloudpickle (from -r requirements.txt (line 7))\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting polygon-api-client (from -r requirements.txt (line 8))\n",
      "  Downloading polygon_api_client-1.14.5-py3-none-any.whl.metadata (952 bytes)\n",
      "Collecting gym_notices>=0.0.4 (from gym==0.25.2->-r requirements.txt (line 2))\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gymnasium<1.2.0,>=0.29.1 (from stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting torch<3.0,>=2.3 (from stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3->-r requirements.txt (line 1)) (4.7.1)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<1.2.0,>=0.29.1->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1)) (3.9.0)\n",
      "Collecting typing-extensions>=4.3.0 (from gymnasium<1.2.0,>=0.29.1->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1)) (2023.9.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1))\n",
      "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.10/site-packages (from triton==3.3.0->torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1)) (68.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.3)\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 6))\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 6))\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 6))\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r requirements.txt (line 6))\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 6))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 6))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: certifi<2026.0.0,>=2022.5.18 in /opt/conda/lib/python3.10/site-packages (from polygon-api-client->-r requirements.txt (line 8)) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.9 in /opt/conda/lib/python3.10/site-packages (from polygon-api-client->-r requirements.txt (line 8)) (1.26.16)\n",
      "Collecting websockets<15.0,>=10.3 (from polygon-api-client->-r requirements.txt (line 8))\n",
      "  Downloading websockets-14.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (2.1.1)\n",
      "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
      "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading polygon_api_client-1.14.5-py3-none-any.whl (44 kB)\n",
      "Downloading websockets-14.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl (320 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.25.2-py3-none-any.whl size=852394 sha256=65a8f673c61c26ca934a175be58646f684ee76d0a894331968d8cf273af5585e\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/95/2c/ee47a8d43fda6a851e340e77e27cf75b49ff4ce2d1540c0e80\n",
      "Successfully built gym\n",
      "Installing collected packages: nvidia-cusparselt-cu12, gym_notices, farama-notifications, werkzeug, websockets, typing-extensions, triton, tensorboard-data-server, sympy, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markdown, grpcio, cloudpickle, absl-py, tensorboard, polygon-api-client, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, gymnasium, gym, nvidia-cusolver-cu12, torch, stable-baselines3\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/33\u001b[0m [werkzeug]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.7.1━━━━━━\u001b[0m \u001b[32m 3/33\u001b[0m [werkzeug]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.7.1:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/33\u001b[0m [werkzeug]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.7.1━━━━━━━━━━━━\u001b[0m \u001b[32m 5/33\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/33\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: triton 2.1.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/33\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling triton-2.1.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/33\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled triton-2.1.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/33\u001b[0m [triton]nsions]\n",
      "\u001b[2K  Attempting uninstall: sympy\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/33\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.11.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/33\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.11.1:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/33\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.11.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/33\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m30/33\u001b[0m [nvidia-cusolver-cu12]2]\n",
      "\u001b[2K    Found existing installation: torch 2.1.0\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m30/33\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.1.0:━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m30/33\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.1.0━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m31/33\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/33\u001b[0m [stable-baselines3]stable-baselines3]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.2.2 cloudpickle-3.1.1 farama-notifications-0.0.4 grpcio-1.71.0 gym-0.25.2 gym_notices-0.0.8 gymnasium-1.1.1 markdown-3.8 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 polygon-api-client-1.14.5 protobuf-6.31.0 stable-baselines3-2.6.0 sympy-1.12 tensorboard-2.19.0 tensorboard-data-server-0.7.2 torch-2.7.0 triton-3.3.0 typing-extensions-4.13.2 websockets-14.2 werkzeug-3.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## Install dependencies\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run integration test script\n",
    "#! pytest tests/integration/test_integration.py --maxfail=1 --disable-warnings -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f04b7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching NVDA from 2023-01-01 to 2023-08-31 (5 minute)...\n",
      "Saved NVDA_5minute to data/NVDA_5minute.csv\n",
      "Fetching NVDA from 2023-01-01 to 2023-08-31 (1 day)...\n",
      "Saved NVDA_1day to data/NVDA_1day.csv\n",
      "Fetching NVDA from 2023-01-01 to 2023-08-31 (1 week)...\n",
      "Saved NVDA_1week to data/NVDA_1week.csv\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "## Generate Training Data\n",
    "! python data_gen/generate_data.py --tickers-file data_gen/tickers.txt --interval 5min --start 2023-01-01 --end 2023-08-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5c4450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ─── Plot all 1day CSVs in data/ ─────────────────────────────────────────\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Grab every CSV matching *_1day.csv\n",
    "csv_files = glob.glob(\"data/*_1day.csv\")\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No files found: data/*_1day.csv\")\n",
    "\n",
    "# 2. Loop and plot\n",
    "for file_path in sorted(csv_files):\n",
    "    # Load and parse time\n",
    "    df = pd.read_csv(file_path, parse_dates=[0])\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "    # Extract ticker from filename\n",
    "    ticker = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df.index, df[\"close\"], linewidth=1)\n",
    "    plt.title(f\"{ticker} 1-Day Close Price\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2abe0554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shimmy\n",
      "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from shimmy) (1.26.0)\n",
      "Requirement already satisfied: gymnasium>=1.0.0a1 in /opt/conda/lib/python3.10/site-packages (from shimmy) (1.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
      "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Installing collected packages: shimmy\n",
      "Successfully installed shimmy-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## Install Shimmy for simulating trading environments\n",
    "! pip install shimmy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f341b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Integration Test for PPO\n",
    "#%run train/train_ppo.py --test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc37589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b741897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68aebfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Using NVDA_5minute.csv for NVDA\n",
      "\n",
      "=== DEBUG START ===\n",
      "[DEBUG] CONFIG keys: dict_keys(['env', 'features', 'actions', 'rewards', 'training', 'evaluation', 'logging', 'metrics', 'DEBUG'])\n",
      "[DEBUG] FEATURES in config: [{'type': 'price', 'field': 'close', 'normalize': True, 'method': 'zscore'}, {'type': 'price', 'field': 'volume', 'normalize': True, 'method': 'rolling_zscore', 'window': 20}, {'type': 'indicator', 'field': 'vwap', 'normalize': True, 'method': 'zscore'}, {'type': 'indicator', 'field': 'sma', 'source': 'close', 'window': 14, 'normalize': True, 'method': 'rolling_zscore'}, {'type': 'indicator', 'field': 'ema', 'source': 'volume', 'window': 10, 'normalize': True, 'method': 'minmax'}]\n",
      "[DEBUG] DataFrame columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
      "[DEBUG] DataFrame dtypes:\n",
      " timestamp     object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "volume       float64\n",
      "dtype: object\n",
      "[DEBUG] First few rows:\n",
      "              timestamp    open    high     low   close   volume\n",
      "0  2023-01-03 09:00:00  15.070  15.100  14.817  14.895  48630.0\n",
      "1  2023-01-03 09:05:00  14.895  14.895  14.868  14.872  27850.0\n",
      "2  2023-01-03 09:10:00  14.872  14.890  14.872  14.890  44470.0\n",
      "3  2023-01-03 09:15:00  14.890  14.938  14.890  14.900  46120.0\n",
      "4  2023-01-03 09:20:00  14.900  14.949  14.892  14.949  41460.0\n",
      "=== DEBUG END ===\n",
      "\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Strategy-PPO-Bots/env/feature_engineering.py:96: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  series = df[name].fillna(method=\"ffill\").fillna(0)\n",
      "/workspace/Strategy-PPO-Bots/env/feature_engineering.py:96: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  series = df[name].fillna(method=\"ffill\").fillna(0)\n",
      "/workspace/Strategy-PPO-Bots/env/feature_engineering.py:96: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  series = df[name].fillna(method=\"ffill\").fillna(0)\n",
      "/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Callback] Rollout finished at step 2048, Avg Reward: -0.0081, Max Reward: -0.0081\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 205  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 9    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "[Callback] Rollout finished at step 4096, Avg Reward: -0.1251, Max Reward: -0.1251\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010353172 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -2.63       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.249      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.0511      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 6144, Avg Reward: -0.1192, Max Reward: -0.1192\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007693048 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.0334     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.192      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 8192, Avg Reward: 0.0549, Max Reward: 0.0549\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 70         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00682721 |\n",
      "|    clip_fraction        | 0.0455     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -0.103     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.608      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    value_loss           | 2.93       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 10240, Avg Reward: -0.0093, Max Reward: -0.0093\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010975678 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.962      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.204      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 12288, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013086578 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.255      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 0.0521      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 14336, Avg Reward: 0.0025, Max Reward: 0.0025\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016763538 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.244      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.0397      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 16384, Avg Reward: 0.0000, Max Reward: -0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010698623 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.06       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.27       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 18432, Avg Reward: -0.0808, Max Reward: -0.0808\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010813802 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.211      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 20480, Avg Reward: 0.0121, Max Reward: 0.0121\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006328293 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.0413     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.41        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 22528, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013707336 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.797      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.258      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 24576, Avg Reward: -0.0063, Max Reward: -0.0063\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 479        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01483387 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -1.56      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.264     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0419    |\n",
      "|    value_loss           | 0.0302     |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 26624, Avg Reward: 0.0014, Max Reward: 0.0014\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017290063 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.45       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.195      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.0934      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 28672, Avg Reward: 0.0335, Max Reward: 0.0335\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013736206 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -2.14       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.257      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 0.0409      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 30720, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 556         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012932079 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0677     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.448       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 32768, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 608          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020912215 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.0158       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.54         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 477          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 34816, Avg Reward: 0.0002, Max Reward: 0.0002\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 51        |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 670       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0121064 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.06     |\n",
      "|    explained_variance   | -1.56     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.223    |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.0403   |\n",
      "|    value_loss           | 0.337     |\n",
      "---------------------------------------\n",
      "[Callback] Rollout finished at step 36864, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 719         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013328098 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.249      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 38912, Avg Reward: 0.0149, Max Reward: 0.0149\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014235744 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.21       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.239       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 40960, Avg Reward: -0.1431, Max Reward: -0.1431\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 756        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01546972 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | -0.96      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.205     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0389    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 43008, Avg Reward: -0.0126, Max Reward: -0.0126\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014070063 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.715      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0983     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 0.588       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 45056, Avg Reward: 0.0314, Max Reward: 0.0314\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 840         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008991974 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.388      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0585      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 47104, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 899         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015299257 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.617      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.266      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 49152, Avg Reward: -0.0125, Max Reward: -0.0125\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 940         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017759223 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.0981      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.232      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 0.0441      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 51200, Avg Reward: 0.0042, Max Reward: 0.0042\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 957         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018690571 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.232      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 53248, Avg Reward: 0.0096, Max Reward: 0.0096\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 986         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018453706 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -1.07       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.252      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 0.0336      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 55296, Avg Reward: 0.0352, Max Reward: 0.0352\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 1027       |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01060394 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | -0.103     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.44       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 3.27       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 57344, Avg Reward: -0.0579, Max Reward: -0.0579\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1078        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010324609 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.458      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 59392, Avg Reward: -0.0246, Max Reward: -0.0246\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1141        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015604685 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.353      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.238      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0513     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 61440, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1175        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016005512 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.23       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.0418      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 63488, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1192        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021993086 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.252      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.0595      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 65536, Avg Reward: 0.3233, Max Reward: 0.3233\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1221        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017831862 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.264      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 0.0241      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 67584, Avg Reward: -0.0567, Max Reward: -0.0567\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 1265         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084486175 |\n",
      "|    clip_fraction        | 0.0753       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -0.0874      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0195      |\n",
      "|    value_loss           | 19.4         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 69632, Avg Reward: 0.0033, Max Reward: 0.0033\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1320        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011194822 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -1.2        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.087      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 71680, Avg Reward: 0.0023, Max Reward: 0.0023\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1386        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015247163 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.527      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.206      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0521     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 73728, Avg Reward: 0.0024, Max Reward: 0.0024\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1415        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018208291 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -1.54       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.254      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.0722      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 75776, Avg Reward: 0.0059, Max Reward: 0.0059\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1437        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021410927 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.231      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    value_loss           | 0.0438      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 77824, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1468        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022333609 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0495     |\n",
      "|    value_loss           | 0.0199      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 79872, Avg Reward: -0.0192, Max Reward: -0.0192\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1511        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009559214 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 81920, Avg Reward: -0.0040, Max Reward: -0.0040\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1564        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015004188 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | -0.516      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.182      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 0.539       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 83968, Avg Reward: 0.0003, Max Reward: 0.0003\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1629        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018224893 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -1.71       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.251      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 0.0626      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 86016, Avg Reward: -0.0008, Max Reward: -0.0008\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1651        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011322781 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.691      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.217      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 88064, Avg Reward: 0.0241, Max Reward: 0.0241\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1674        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019803688 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.273      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 90112, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1709        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020554189 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    value_loss           | 0.0264      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 92160, Avg Reward: -0.0216, Max Reward: -0.0216\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1755        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004022343 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.0472     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    value_loss           | 762         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 94208, Avg Reward: 0.0043, Max Reward: 0.0043\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 1812         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069615617 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -0.0255      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 96256, Avg Reward: -0.0010, Max Reward: -0.0010\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1881        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014174994 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 98304, Avg Reward: -0.0025, Max Reward: -0.0025\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1897        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010207332 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 100352, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1922        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008338566 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 102400, Avg Reward: 0.0702, Max Reward: 0.0702\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 1958       |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01638957 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0785    |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 0.904      |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 104448, Avg Reward: -0.0160, Max Reward: -0.0160\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 2008         |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069706133 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -0.0855      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 106496, Avg Reward: -0.0103, Max Reward: -0.0103\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 2067        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007962838 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -2.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.357       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 7.86        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 108544, Avg Reward: 0.0013, Max Reward: 0.0013\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 2135        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013447687 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.165      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 110592, Avg Reward: 0.0040, Max Reward: 0.0040\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 2148        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009771837 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.105      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 112640, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 2174        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010335147 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -3.3        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.32        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 114688, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 2211        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019045008 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.114      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 116736, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 2263        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009457489 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.0172     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 118784, Avg Reward: -0.0019, Max Reward: -0.0019\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 2326        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016264385 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.175      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.225      |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 120832, Avg Reward: 0.0027, Max Reward: 0.0027\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 2386        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009400627 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.141      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 122880, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 2401        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013496166 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00397    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.945       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 124928, Avg Reward: 0.0803, Max Reward: 0.0803\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 2426        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013033338 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -1.12       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.183      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 126976, Avg Reward: -0.2959, Max Reward: -0.2959\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 2463        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019908287 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.286      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.178      |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 0.312       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 129024, Avg Reward: -0.0688, Max Reward: -0.0688\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 2512         |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061576553 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -0.0336      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 131072, Avg Reward: 0.0044, Max Reward: 0.0044\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 2573        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013017527 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.235      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 0.0842      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 133120, Avg Reward: 0.0005, Max Reward: 0.0005\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 2625        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008525917 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.128      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 135168, Avg Reward: -0.0176, Max Reward: -0.0176\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 2639        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024884913 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.514      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0782     |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 137216, Avg Reward: 0.0158, Max Reward: 0.0158\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 2667        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018089334 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.225      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.246      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 139264, Avg Reward: 0.0103, Max Reward: 0.0103\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 2704        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014081158 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.432      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.133      |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 0.589       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 141312, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 2754        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007506661 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.925      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.629       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 8.4         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 143360, Avg Reward: -0.0079, Max Reward: -0.0079\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 2813        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012082625 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.198      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 145408, Avg Reward: 0.0145, Max Reward: 0.0145\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 2857         |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074471384 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.113        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.205       |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    value_loss           | 0.111        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 147456, Avg Reward: 0.0031, Max Reward: 0.0031\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 2873        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009880376 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.066       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.185      |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 149504, Avg Reward: -0.1288, Max Reward: -0.1288\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 2900       |\n",
      "|    total_timesteps      | 149504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02454624 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -0.0368    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.224     |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.0828     |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 151552, Avg Reward: -0.0067, Max Reward: -0.0067\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 2938        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012879417 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0239     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 153600, Avg Reward: 0.0061, Max Reward: 0.0061\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 2989        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009633806 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.182      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.545       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 4.69        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 155648, Avg Reward: -0.0037, Max Reward: -0.0037\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 3051       |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01268257 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.52       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.146     |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.287      |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 157696, Avg Reward: -0.0008, Max Reward: -0.0008\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 3090        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010095732 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.135      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 159744, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 3109        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013489032 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.888      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.192      |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 161792, Avg Reward: -0.0910, Max Reward: -0.0910\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 3140        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010305809 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0981     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.225      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 0.0742      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 163840, Avg Reward: 0.0106, Max Reward: 0.0106\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 3183        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013302084 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0903      |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 165888, Avg Reward: 0.0445, Max Reward: 0.0445\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 3237        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012683263 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.649      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0601     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 2.19        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 167936, Avg Reward: 0.0150, Max Reward: 0.0150\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 3300        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017750902 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.654      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.175      |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 169984, Avg Reward: 0.0251, Max Reward: 0.0251\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 3332        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009258154 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0335      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.422       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 172032, Avg Reward: 0.0111, Max Reward: 0.0111\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 3352        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013862709 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.0252      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00656    |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 174080, Avg Reward: -0.0307, Max Reward: -0.0307\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 3383        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013729751 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.261      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    value_loss           | 0.0291      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 176128, Avg Reward: -0.0162, Max Reward: -0.0162\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 3423        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007906001 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.00277     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 178176, Avg Reward: -0.0296, Max Reward: -0.0296\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 3476       |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01516973 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -0.0108    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.0346    |\n",
      "|    value_loss           | 1.03       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 180224, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 3541        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011554262 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.144      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 182272, Avg Reward: 0.0002, Max Reward: 0.0002\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 3565         |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053220275 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0668       |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 0.342        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 184320, Avg Reward: 0.0070, Max Reward: 0.0070\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 3584        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010068866 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.199      |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 186368, Avg Reward: -0.0023, Max Reward: -0.0023\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 3615        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013584579 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.26       |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 0.0542      |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 188416, Avg Reward: 0.0115, Max Reward: 0.0115\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 3656         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035032053 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 2.17e+03     |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 190464, Avg Reward: 0.0043, Max Reward: 0.0043\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 3710         |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030229301 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.953       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 192512, Avg Reward: -0.0051, Max Reward: -0.0051\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 3775        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004893277 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.039      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.51        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 194560, Avg Reward: 0.0065, Max Reward: 0.0065\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 3793         |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058619697 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0581      |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00872     |\n",
      "|    value_loss           | 0.742        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 196608, Avg Reward: 0.0230, Max Reward: 0.0230\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 3815         |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025366603 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -1.79        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 57.2         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    value_loss           | 416          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 198656, Avg Reward: -0.0737, Max Reward: -0.0737\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 3848        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012756419 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.14       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 6.88        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 200704, Avg Reward: -0.0059, Max Reward: -0.0059\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 3894        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008064417 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 202752, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 3951        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010397536 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 8.23        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 204800, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 4017         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064130807 |\n",
      "|    clip_fraction        | 0.0709       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.111       |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0228      |\n",
      "|    value_loss           | 0.801        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 206848, Avg Reward: -0.0012, Max Reward: -0.0012\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 4029        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017009567 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.608       |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | 0.000352    |\n",
      "|    value_loss           | 0.95        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 208896, Avg Reward: 0.0176, Max Reward: 0.0176\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 4053        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012144612 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | -0.302      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.93        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 210944, Avg Reward: -0.0136, Max Reward: -0.0136\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 4089        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019651596 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 212992, Avg Reward: 0.0591, Max Reward: 0.0591\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 4134        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008261868 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.12        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 215040, Avg Reward: 0.0050, Max Reward: 0.0050\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 4192        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015188228 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.784       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 217088, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 4254        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770483 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.778      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0155      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.947       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 219136, Avg Reward: 0.0002, Max Reward: 0.0002\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 4267        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011527576 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 221184, Avg Reward: 0.0199, Max Reward: 0.0199\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 4291        |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011057369 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.151      |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.988       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 223232, Avg Reward: -0.0404, Max Reward: -0.0404\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 4327        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021295471 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.653      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0749     |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 225280, Avg Reward: -0.0061, Max Reward: -0.0061\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 4373         |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091208415 |\n",
      "|    clip_fraction        | 0.0703       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.44         |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 8.97         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 227328, Avg Reward: 0.0098, Max Reward: 0.0098\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 4432         |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096158665 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -0.131       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.204       |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.0289      |\n",
      "|    value_loss           | 0.271        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 229376, Avg Reward: -0.0011, Max Reward: -0.0011\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 4486         |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039103376 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.137       |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 0.338        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 231424, Avg Reward: -0.0034, Max Reward: -0.0034\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 4499         |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068977624 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0894       |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 1.1          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 233472, Avg Reward: -0.0197, Max Reward: -0.0197\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 4527        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013488989 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.0787     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.224      |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 235520, Avg Reward: -0.0029, Max Reward: -0.0029\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 4563       |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02067937 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | -0.186     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.14      |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.039     |\n",
      "|    value_loss           | 1.16       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 237568, Avg Reward: -0.0161, Max Reward: -0.0161\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 4613        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011380204 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.0231     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 239616, Avg Reward: -0.0011, Max Reward: -0.0011\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 4672        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018038739 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.698      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.218      |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 241664, Avg Reward: 0.0029, Max Reward: 0.0029\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 4720         |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037030522 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.647       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0684       |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    value_loss           | 0.421        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 243712, Avg Reward: 0.0070, Max Reward: 0.0070\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 4735         |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068964227 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00472     |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.0217      |\n",
      "|    value_loss           | 1.08         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 245760, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 4764        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032843135 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.14       |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.321       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 247808, Avg Reward: -0.0150, Max Reward: -0.0150\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 4805        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012779277 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.677      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 0.953       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 249856, Avg Reward: 0.0358, Max Reward: 0.0358\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 4858       |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837227 |\n",
      "|    clip_fraction        | 0.0579     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.909      |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    value_loss           | 3.56       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 251904, Avg Reward: -0.0037, Max Reward: -0.0037\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 4924         |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076243286 |\n",
      "|    clip_fraction        | 0.0644       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0332      |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.023       |\n",
      "|    value_loss           | 0.619        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 253952, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 4966         |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061833835 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 256000, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 4983        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009476557 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00603    |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 0.789       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 258048, Avg Reward: -0.0156, Max Reward: -0.0156\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 5013        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031229526 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.156      |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 260096, Avg Reward: -0.0372, Max Reward: -0.0372\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 5054        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010571995 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.16       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0871     |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 262144, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 5107        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012151992 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.0862     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0795      |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 264192, Avg Reward: 0.0118, Max Reward: 0.0118\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 5172        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009647522 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.132      |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 266240, Avg Reward: 0.0015, Max Reward: 0.0015\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 5207         |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046439064 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.106       |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 0.857        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 268288, Avg Reward: -0.2187, Max Reward: -0.2187\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 5226        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009568849 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 0.476       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 270336, Avg Reward: -0.1824, Max Reward: -0.1824\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 5259        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019244997 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.219      |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 272384, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 5301         |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030582827 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00972     |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 274432, Avg Reward: 0.0203, Max Reward: 0.0203\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 5358         |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029459926 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.12         |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 11.9         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 276480, Avg Reward: -0.0026, Max Reward: -0.0026\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 5423        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007917978 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.914      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.48        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.98        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 278528, Avg Reward: -0.0034, Max Reward: -0.0034\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 5452       |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00085263 |\n",
      "|    clip_fraction        | 9.77e-05   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0.513      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.24       |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.00207   |\n",
      "|    value_loss           | 1.51       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 280576, Avg Reward: 0.0174, Max Reward: 0.0174\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 5472        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009088401 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.135      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.912       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 282624, Avg Reward: -0.0431, Max Reward: -0.0431\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 5505        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011545328 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 284672, Avg Reward: -0.0642, Max Reward: -0.0642\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 5550        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004674065 |\n",
      "|    clip_fraction        | 0.00928     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0386     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 286720, Avg Reward: 0.0028, Max Reward: 0.0028\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 5605        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422486 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -1.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.64        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 288768, Avg Reward: 0.0003, Max Reward: 0.0003\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 5672        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005696481 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.048       |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 290816, Avg Reward: 0.0014, Max Reward: 0.0014\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 5694        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009108772 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.174      |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 292864, Avg Reward: -0.0503, Max Reward: -0.0503\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 5715         |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039876876 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -2.57        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.32         |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 6.84         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 294912, Avg Reward: -0.0154, Max Reward: -0.0154\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 5750        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016319918 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -2.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.182      |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 296960, Avg Reward: 0.0040, Max Reward: 0.0040\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 5796        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006952402 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.884      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.44        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 299008, Avg Reward: 0.0050, Max Reward: 0.0050\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 5853         |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071504954 |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.088        |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.0255      |\n",
      "|    value_loss           | 2.46         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 301056, Avg Reward: -0.0135, Max Reward: -0.0135\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 147        |\n",
      "|    time_elapsed         | 5923       |\n",
      "|    total_timesteps      | 301056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01636149 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.546      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0381    |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | -0.00341   |\n",
      "|    value_loss           | 0.46       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 303104, Avg Reward: -0.0027, Max Reward: -0.0027\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 5935       |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10883446 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | -0.108     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.81       |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | 0.00593    |\n",
      "|    value_loss           | 1.48       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 305152, Avg Reward: 0.1403, Max Reward: 0.1403\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 5958        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006244144 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.586      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.168      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 307200, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 5991        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008766517 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.137      |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.452       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 309248, Avg Reward: 0.0373, Max Reward: 0.0373\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 6036         |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032470755 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.0269      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25         |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00931     |\n",
      "|    value_loss           | 271          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 311296, Avg Reward: -0.0343, Max Reward: -0.0343\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 6091         |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054956423 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -1.59        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84         |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 313344, Avg Reward: -0.0049, Max Reward: -0.0049\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 6153        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002990841 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.33        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    value_loss           | 0.924       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 315392, Avg Reward: 0.0046, Max Reward: 0.0046\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 6164        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001654679 |\n",
      "|    clip_fraction        | 0.00151     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.59        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    value_loss           | 6.5         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 317440, Avg Reward: -0.0461, Max Reward: -0.0461\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 6188         |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043324786 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -2.65        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.91         |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    value_loss           | 15.8         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 319488, Avg Reward: 0.0133, Max Reward: 0.0133\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 6224        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016347071 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.163      |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 321536, Avg Reward: 0.0043, Max Reward: 0.0043\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 6273         |\n",
      "|    total_timesteps      | 321536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038212445 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.216       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 323584, Avg Reward: 0.0032, Max Reward: 0.0032\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 6332         |\n",
      "|    total_timesteps      | 323584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034459902 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.082        |\n",
      "|    n_updates            | 1570         |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    value_loss           | 0.78         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 325632, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 6389        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011271174 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.029      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.428       |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 327680, Avg Reward: -0.0220, Max Reward: -0.0220\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 6404         |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053024804 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0747       |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 2.04         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 329728, Avg Reward: 0.1755, Max Reward: 0.1755\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 6429         |\n",
      "|    total_timesteps      | 329728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042696265 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.481        |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    value_loss           | 0.834        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 331776, Avg Reward: -0.0060, Max Reward: -0.0060\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 6468        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013534989 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.205      |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.3         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 333824, Avg Reward: 0.0790, Max Reward: 0.0790\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 6518        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006984899 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.273      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.19        |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 335872, Avg Reward: 0.0020, Max Reward: 0.0020\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 6579        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008263061 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.699       |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 337920, Avg Reward: -0.0020, Max Reward: -0.0020\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 6631         |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012619685 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 339968, Avg Reward: -0.0012, Max Reward: -0.0012\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 6646         |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056662727 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0659       |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 342016, Avg Reward: 0.1390, Max Reward: 0.1390\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 6674        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011778571 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.126      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.916       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 344064, Avg Reward: 0.0082, Max Reward: 0.0082\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 6713        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017796975 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0812     |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 0.392       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 346112, Avg Reward: 0.0667, Max Reward: 0.0667\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 6765         |\n",
      "|    total_timesteps      | 346112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039914786 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -0.165       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 46           |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 348160, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 6830        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012240822 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00363     |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.439       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 350208, Avg Reward: 0.0006, Max Reward: 0.0006\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 6875        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003785047 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.133      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 352256, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 6893        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005722862 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 6.33        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 354304, Avg Reward: -0.0035, Max Reward: -0.0035\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 6922        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007160854 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.533       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 356352, Avg Reward: 0.0067, Max Reward: 0.0067\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 6964        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012465358 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.379       |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 4.95        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 358400, Avg Reward: 0.0032, Max Reward: 0.0032\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 7019        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009148436 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.535      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 360448, Avg Reward: 0.0022, Max Reward: 0.0022\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 176        |\n",
      "|    time_elapsed         | 7083       |\n",
      "|    total_timesteps      | 360448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01041434 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -0.252     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.202     |\n",
      "|    n_updates            | 1750       |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.249      |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 362496, Avg Reward: 0.0024, Max Reward: 0.0024\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 7122        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009683853 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.172      |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | 0.00026     |\n",
      "|    value_loss           | 0.922       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 364544, Avg Reward: 0.0914, Max Reward: 0.0914\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 7139        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009832336 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.57        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 2.24        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 366592, Avg Reward: 0.1698, Max Reward: 0.1698\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 7169        |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019294528 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.22       |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.382       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 368640, Avg Reward: 0.0271, Max Reward: 0.0271\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 7211        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013525814 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 370688, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 7263        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010819075 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 372736, Avg Reward: -0.0030, Max Reward: -0.0030\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 7328         |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045442567 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.114       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.176       |\n",
      "|    n_updates            | 1810         |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    value_loss           | 0.511        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 374784, Avg Reward: -0.0102, Max Reward: -0.0102\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 7360        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006135693 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.144      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    value_loss           | 1.88        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 376832, Avg Reward: 0.0015, Max Reward: 0.0015\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 7378        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007988768 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 378880, Avg Reward: 0.0415, Max Reward: 0.0415\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 7408        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009872942 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.226      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 380928, Avg Reward: -0.0334, Max Reward: -0.0334\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 7451        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008738875 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 382976, Avg Reward: 0.0110, Max Reward: 0.0110\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 7506        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011092783 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.82       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00394    |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 385024, Avg Reward: -0.0040, Max Reward: -0.0040\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 7571        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005063834 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.677       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 387072, Avg Reward: -0.0002, Max Reward: -0.0002\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 7597         |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019173933 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 1880         |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 2.19         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 389120, Avg Reward: 0.0074, Max Reward: 0.0074\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 7618        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008276265 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.42       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 0.958       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 391168, Avg Reward: -0.0117, Max Reward: -0.0117\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 7650        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027607411 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.145      |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 393216, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 7695        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011914513 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0772      |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 395264, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 7750        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012805093 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -1.18       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0449      |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 397312, Avg Reward: -0.0006, Max Reward: -0.0006\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 7819         |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054552224 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.195       |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 0.692        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 399360, Avg Reward: -0.0065, Max Reward: -0.0065\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 7837         |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073499028 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0592       |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 2.14         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 401408, Avg Reward: 0.0738, Max Reward: 0.0738\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 7859        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013533946 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0317      |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.77        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 403456, Avg Reward: 0.0036, Max Reward: 0.0036\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 7894        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011020258 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.233      |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 405504, Avg Reward: 0.0076, Max Reward: 0.0076\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 7939        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008903359 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.299      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 407552, Avg Reward: 0.0012, Max Reward: 0.0012\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 7996        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009901287 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -1.73       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 409600, Avg Reward: -0.0026, Max Reward: -0.0026\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 8065        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007741954 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.442      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0567     |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 411648, Avg Reward: 0.0117, Max Reward: 0.0117\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 201          |\n",
      "|    time_elapsed         | 8077         |\n",
      "|    total_timesteps      | 411648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024853027 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.178       |\n",
      "|    n_updates            | 2000         |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    value_loss           | 0.85         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 413696, Avg Reward: 0.2737, Max Reward: 0.2737\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 8099        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006908223 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.876      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 415744, Avg Reward: 0.1058, Max Reward: 0.1058\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 8134        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024586419 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.186      |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.835       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 417792, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 8181        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009725057 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 9.88        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 419840, Avg Reward: 0.0010, Max Reward: 0.0010\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 8242         |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061420407 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0606      |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    value_loss           | 0.61         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 421888, Avg Reward: -0.0056, Max Reward: -0.0056\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 206          |\n",
      "|    time_elapsed         | 8305         |\n",
      "|    total_timesteps      | 421888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020723129 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.121        |\n",
      "|    n_updates            | 2050         |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    value_loss           | 0.615        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 423936, Avg Reward: 0.0005, Max Reward: 0.0005\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 8317         |\n",
      "|    total_timesteps      | 423936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016024245 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.87         |\n",
      "|    n_updates            | 2060         |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 4.3          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 425984, Avg Reward: 0.0255, Max Reward: 0.0255\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 8341         |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065856352 |\n",
      "|    clip_fraction        | 0.0803       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.159       |\n",
      "|    n_updates            | 2070         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.479        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 428032, Avg Reward: -0.0580, Max Reward: -0.0580\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 8379        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016453844 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.78        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 430080, Avg Reward: 0.0819, Max Reward: 0.0819\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 8427         |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031901547 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -0.0443      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 58.9         |\n",
      "|    n_updates            | 2090         |\n",
      "|    policy_gradient_loss | -0.00858     |\n",
      "|    value_loss           | 1.12e+03     |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 432128, Avg Reward: -0.0252, Max Reward: -0.0252\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 8487         |\n",
      "|    total_timesteps      | 432128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042306255 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.891       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.989        |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    value_loss           | 2.7          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 434176, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 8543        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004011627 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.54        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 436224, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 213          |\n",
      "|    time_elapsed         | 8559         |\n",
      "|    total_timesteps      | 436224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025156057 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.825        |\n",
      "|    n_updates            | 2120         |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 4            |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 438272, Avg Reward: -0.0449, Max Reward: -0.0449\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 8584        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015452891 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0954     |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 440320, Avg Reward: -0.0012, Max Reward: -0.0012\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 8621        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011571513 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -2.68       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 442368, Avg Reward: -0.0196, Max Reward: -0.0196\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 8670       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00788984 |\n",
      "|    clip_fraction        | 0.0556     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.52       |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 444416, Avg Reward: 0.0017, Max Reward: 0.0017\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 8729         |\n",
      "|    total_timesteps      | 444416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032274206 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.161        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0931       |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 0.816        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 446464, Avg Reward: -0.0022, Max Reward: -0.0022\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 8776        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004385839 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 448512, Avg Reward: -0.0349, Max Reward: -0.0349\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 8792         |\n",
      "|    total_timesteps      | 448512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028934276 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.992        |\n",
      "|    n_updates            | 2180         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 1.69         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 450560, Avg Reward: -0.0995, Max Reward: -0.0995\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 8819        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436837 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0842     |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.406       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 452608, Avg Reward: -0.0287, Max Reward: -0.0287\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 8857        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013616428 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.184      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0471     |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.882       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 454656, Avg Reward: -0.1348, Max Reward: -0.1348\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 8907        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007265604 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 6.34        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 456704, Avg Reward: -0.0045, Max Reward: -0.0045\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 8967         |\n",
      "|    total_timesteps      | 456704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077622076 |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.47        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 2220         |\n",
      "|    policy_gradient_loss | -0.0196      |\n",
      "|    value_loss           | 0.873        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 458752, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 9007         |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062532057 |\n",
      "|    clip_fraction        | 0.0835       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.178       |\n",
      "|    n_updates            | 2230         |\n",
      "|    policy_gradient_loss | -0.00791     |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 460800, Avg Reward: 0.0129, Max Reward: 0.0129\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 9024        |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004770945 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 2.41        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 462848, Avg Reward: -0.0012, Max Reward: -0.0012\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 9053        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008231928 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.203      |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.696       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 464896, Avg Reward: 0.0176, Max Reward: 0.0176\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 9092        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011839278 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 466944, Avg Reward: -0.1519, Max Reward: -0.1519\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 9143        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006942713 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0637     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.999       |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 468992, Avg Reward: -0.0009, Max Reward: -0.0009\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 9205        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009632751 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.049      |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.789       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 471040, Avg Reward: 0.0015, Max Reward: 0.0015\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 9239         |\n",
      "|    total_timesteps      | 471040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010736352 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.57         |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    value_loss           | 4.46         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 473088, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 9257        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003483984 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0847      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 6.37        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 475136, Avg Reward: -0.0926, Max Reward: -0.0926\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 9289        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015354503 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.776       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 477184, Avg Reward: -0.0046, Max Reward: -0.0046\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 9333        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006739172 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.585       |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 479232, Avg Reward: -0.0055, Max Reward: -0.0055\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 9388        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009715281 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 481280, Avg Reward: -0.0022, Max Reward: -0.0022\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 235          |\n",
      "|    time_elapsed         | 9458         |\n",
      "|    total_timesteps      | 481280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040273466 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0953       |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 0.749        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 483328, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 9486        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008885378 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.137      |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    value_loss           | 6.35        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 485376, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 9506        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003030348 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1         |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    value_loss           | 5.59        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 487424, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 9538         |\n",
      "|    total_timesteps      | 487424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046158107 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0184      |\n",
      "|    n_updates            | 2370         |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 489472, Avg Reward: -0.0027, Max Reward: -0.0027\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 9580        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007040575 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.26        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 491520, Avg Reward: -0.0087, Max Reward: -0.0087\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 9636        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008090432 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 7.71        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 493568, Avg Reward: -0.0012, Max Reward: -0.0012\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 9703        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003975371 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0601     |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.433       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 495616, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 242           |\n",
      "|    time_elapsed         | 9724          |\n",
      "|    total_timesteps      | 495616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051386596 |\n",
      "|    clip_fraction        | 0.000684      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.737         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.391         |\n",
      "|    n_updates            | 2410          |\n",
      "|    policy_gradient_loss | -0.0028       |\n",
      "|    value_loss           | 0.748         |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 497664, Avg Reward: 0.0315, Max Reward: 0.0315\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 9745         |\n",
      "|    total_timesteps      | 497664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050484426 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.39         |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 499712, Avg Reward: 0.1071, Max Reward: 0.1071\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 9778        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014588229 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0417     |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.782       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 501760, Avg Reward: -0.0395, Max Reward: -0.0395\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 9824        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004768179 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.57        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 503808, Avg Reward: 0.0036, Max Reward: 0.0036\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 9880        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005285261 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23        |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 505856, Avg Reward: -0.0079, Max Reward: -0.0079\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 9946         |\n",
      "|    total_timesteps      | 505856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009405954 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 2460         |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 507904, Avg Reward: 0.0007, Max Reward: 0.0007\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 248           |\n",
      "|    time_elapsed         | 9961          |\n",
      "|    total_timesteps      | 507904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1131705e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.812         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.34          |\n",
      "|    n_updates            | 2470          |\n",
      "|    policy_gradient_loss | -0.000538     |\n",
      "|    value_loss           | 6.71          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 509952, Avg Reward: 0.3186, Max Reward: 0.3186\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 9982        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005001677 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 512000, Avg Reward: -0.0368, Max Reward: -0.0368\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 250        |\n",
      "|    time_elapsed         | 10016      |\n",
      "|    total_timesteps      | 512000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00984055 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.575      |\n",
      "|    n_updates            | 2490       |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    value_loss           | 8.3        |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 514048, Avg Reward: -0.0016, Max Reward: -0.0016\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 251        |\n",
      "|    time_elapsed         | 10061      |\n",
      "|    total_timesteps      | 514048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00470354 |\n",
      "|    clip_fraction        | 0.0297     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -0.416     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 2500       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 47.6       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 516096, Avg Reward: 0.0015, Max Reward: 0.0015\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 10117        |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043914355 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.452        |\n",
      "|    n_updates            | 2510         |\n",
      "|    policy_gradient_loss | -0.0214      |\n",
      "|    value_loss           | 2.16         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 518144, Avg Reward: -0.0018, Max Reward: -0.0018\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 10179       |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006021422 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.757       |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 520192, Avg Reward: -0.0034, Max Reward: -0.0034\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 254          |\n",
      "|    time_elapsed         | 10192        |\n",
      "|    total_timesteps      | 520192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004269613 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.23         |\n",
      "|    n_updates            | 2530         |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    value_loss           | 3.76         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 522240, Avg Reward: -0.0428, Max Reward: -0.0428\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 10215       |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006064422 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.118      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.843       |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 4.94        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 524288, Avg Reward: 0.0547, Max Reward: 0.0547\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 10250       |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008691065 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00631    |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 526336, Avg Reward: -0.0959, Max Reward: -0.0959\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 10296       |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007233835 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 528384, Avg Reward: -0.0015, Max Reward: -0.0015\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 10355       |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004791565 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 530432, Avg Reward: 0.0153, Max Reward: 0.0153\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 10414       |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002747255 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    value_loss           | 1.75        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 532480, Avg Reward: -0.0215, Max Reward: -0.0215\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 10429        |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011270908 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0544      |\n",
      "|    n_updates            | 2590         |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 534528, Avg Reward: -0.0091, Max Reward: -0.0091\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 10455        |\n",
      "|    total_timesteps      | 534528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041675204 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.337       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0746      |\n",
      "|    n_updates            | 2600         |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    value_loss           | 0.584        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 536576, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 10491       |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015250126 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0972     |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 0.586       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 538624, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 10542        |\n",
      "|    total_timesteps      | 538624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074620163 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    value_loss           | 6.77         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 540672, Avg Reward: -0.0028, Max Reward: -0.0028\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 264          |\n",
      "|    time_elapsed         | 10603        |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025803251 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.157        |\n",
      "|    n_updates            | 2630         |\n",
      "|    policy_gradient_loss | -0.00996     |\n",
      "|    value_loss           | 0.884        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 542720, Avg Reward: -0.0067, Max Reward: -0.0067\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 10655        |\n",
      "|    total_timesteps      | 542720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008200017 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 2640         |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 544768, Avg Reward: 0.0213, Max Reward: 0.0213\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 266          |\n",
      "|    time_elapsed         | 10670        |\n",
      "|    total_timesteps      | 544768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007424302 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.922        |\n",
      "|    n_updates            | 2650         |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 546816, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 267          |\n",
      "|    time_elapsed         | 10696        |\n",
      "|    total_timesteps      | 546816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045720153 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.131       |\n",
      "|    n_updates            | 2660         |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    value_loss           | 0.206        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 548864, Avg Reward: 0.0171, Max Reward: 0.0171\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 10733       |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008342657 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.901      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0712     |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 550912, Avg Reward: -0.1273, Max Reward: -0.1273\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 10780       |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003857143 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0965     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 552960, Avg Reward: 0.0197, Max Reward: 0.0197\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 10838        |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047421213 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.209       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.197        |\n",
      "|    n_updates            | 2690         |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    value_loss           | 0.787        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 555008, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 10882       |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002648889 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.6         |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 557056, Avg Reward: 0.0223, Max Reward: 0.0223\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 10899        |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021322225 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 2710         |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    value_loss           | 4.16         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 559104, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 10928        |\n",
      "|    total_timesteps      | 559104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041096625 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0612       |\n",
      "|    n_updates            | 2720         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 561152, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 10967       |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009467177 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11        |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 5.18        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 563200, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 11017        |\n",
      "|    total_timesteps      | 563200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060002133 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -7           |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.83         |\n",
      "|    n_updates            | 2740         |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    value_loss           | 265          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 565248, Avg Reward: -0.0127, Max Reward: -0.0127\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 11079       |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009222724 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0577     |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.83        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 567296, Avg Reward: -0.0022, Max Reward: -0.0022\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 11117        |\n",
      "|    total_timesteps      | 567296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031361843 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0104       |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.000357    |\n",
      "|    value_loss           | 3.1          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 569344, Avg Reward: 0.0991, Max Reward: 0.0991\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 11135        |\n",
      "|    total_timesteps      | 569344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024779239 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.57         |\n",
      "|    n_updates            | 2770         |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    value_loss           | 7.84         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 571392, Avg Reward: -0.1018, Max Reward: -0.1018\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 279          |\n",
      "|    time_elapsed         | 11164        |\n",
      "|    total_timesteps      | 571392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045514824 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00641     |\n",
      "|    n_updates            | 2780         |\n",
      "|    policy_gradient_loss | -0.00841     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 573440, Avg Reward: -0.0140, Max Reward: -0.0140\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 280          |\n",
      "|    time_elapsed         | 11204        |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089877555 |\n",
      "|    clip_fraction        | 0.0821       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.261        |\n",
      "|    n_updates            | 2790         |\n",
      "|    policy_gradient_loss | -0.0298      |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 575488, Avg Reward: 0.0132, Max Reward: 0.0132\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 11256       |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008358488 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -4.06       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.482       |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 577536, Avg Reward: 0.0019, Max Reward: 0.0019\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 11320       |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006087992 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.225      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 579584, Avg Reward: 0.0110, Max Reward: 0.0110\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 11352        |\n",
      "|    total_timesteps      | 579584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031971242 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.95        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.296        |\n",
      "|    n_updates            | 2820         |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 581632, Avg Reward: -0.0050, Max Reward: -0.0050\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 284        |\n",
      "|    time_elapsed         | 11372      |\n",
      "|    total_timesteps      | 581632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00442383 |\n",
      "|    clip_fraction        | 0.0117     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.8        |\n",
      "|    n_updates            | 2830       |\n",
      "|    policy_gradient_loss | -0.00854   |\n",
      "|    value_loss           | 2.83       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 583680, Avg Reward: 0.0880, Max Reward: 0.0880\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 11403       |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011705393 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0956     |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 585728, Avg Reward: -0.0133, Max Reward: -0.0133\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 11444       |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009228373 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.628      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 4.46        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 587776, Avg Reward: 0.0053, Max Reward: 0.0053\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 11497       |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005361221 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 589824, Avg Reward: -0.0166, Max Reward: -0.0166\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 11563       |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005548388 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.84        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 591872, Avg Reward: 0.0002, Max Reward: 0.0002\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 289          |\n",
      "|    time_elapsed         | 11587        |\n",
      "|    total_timesteps      | 591872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053607416 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.0729       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0971      |\n",
      "|    n_updates            | 2880         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 593920, Avg Reward: 0.0000, Max Reward: -0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 11609       |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004746255 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 595968, Avg Reward: -0.0058, Max Reward: -0.0058\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 11641       |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003437827 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.137      |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    value_loss           | 2.31        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 598016, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 11684       |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011887143 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 8.18        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 600064, Avg Reward: -0.0023, Max Reward: -0.0023\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 293          |\n",
      "|    time_elapsed         | 11740        |\n",
      "|    total_timesteps      | 600064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060334327 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.369        |\n",
      "|    n_updates            | 2920         |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 602112, Avg Reward: -0.0054, Max Reward: -0.0054\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 11808       |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014833406 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 604160, Avg Reward: -0.0048, Max Reward: -0.0048\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 11826        |\n",
      "|    total_timesteps      | 604160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044217026 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.42         |\n",
      "|    n_updates            | 2940         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 4.78         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 606208, Avg Reward: 0.0933, Max Reward: 0.0933\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 11847       |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004909887 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 608256, Avg Reward: -0.0648, Max Reward: -0.0648\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 11879        |\n",
      "|    total_timesteps      | 608256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045143245 |\n",
      "|    clip_fraction        | 0.0694       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0982       |\n",
      "|    n_updates            | 2960         |\n",
      "|    policy_gradient_loss | -0.00862     |\n",
      "|    value_loss           | 0.526        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 610304, Avg Reward: 0.0442, Max Reward: 0.0442\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 51        |\n",
      "|    iterations           | 298       |\n",
      "|    time_elapsed         | 11924     |\n",
      "|    total_timesteps      | 610304    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0086127 |\n",
      "|    clip_fraction        | 0.0625    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | -0.038    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.99      |\n",
      "|    n_updates            | 2970      |\n",
      "|    policy_gradient_loss | -0.0248   |\n",
      "|    value_loss           | 8.83      |\n",
      "---------------------------------------\n",
      "[Callback] Rollout finished at step 612352, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 11980        |\n",
      "|    total_timesteps      | 612352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053850412 |\n",
      "|    clip_fraction        | 0.0523       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0919       |\n",
      "|    n_updates            | 2980         |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 614400, Avg Reward: -0.0040, Max Reward: -0.0040\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 12048       |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007832284 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    value_loss           | 2.06        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 616448, Avg Reward: -0.0018, Max Reward: -0.0018\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 301          |\n",
      "|    time_elapsed         | 12059        |\n",
      "|    total_timesteps      | 616448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019886545 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 3000         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 618496, Avg Reward: 0.1826, Max Reward: 0.1826\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 12082        |\n",
      "|    total_timesteps      | 618496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024512797 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00455      |\n",
      "|    n_updates            | 3010         |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 620544, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 12118       |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009020954 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.183      |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.596       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 622592, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 12164        |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045813774 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.1          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95         |\n",
      "|    n_updates            | 3030         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 624640, Avg Reward: -0.0021, Max Reward: -0.0021\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 12222        |\n",
      "|    total_timesteps      | 624640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050187847 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.601        |\n",
      "|    n_updates            | 3040         |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 2.73         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 626688, Avg Reward: -0.0162, Max Reward: -0.0162\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 306          |\n",
      "|    time_elapsed         | 12284        |\n",
      "|    total_timesteps      | 626688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010259078 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.22         |\n",
      "|    n_updates            | 3050         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 6.08         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 628736, Avg Reward: -0.0002, Max Reward: -0.0002\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 307           |\n",
      "|    time_elapsed         | 12297         |\n",
      "|    total_timesteps      | 628736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043369803 |\n",
      "|    clip_fraction        | 0.00181       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.203         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.51          |\n",
      "|    n_updates            | 3060          |\n",
      "|    policy_gradient_loss | -0.0037       |\n",
      "|    value_loss           | 11.4          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 630784, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 12321        |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018086894 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0762       |\n",
      "|    n_updates            | 3070         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 632832, Avg Reward: 0.1327, Max Reward: 0.1327\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 12358        |\n",
      "|    total_timesteps      | 632832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061821444 |\n",
      "|    clip_fraction        | 0.059        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.187        |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | -0.0226      |\n",
      "|    value_loss           | 0.866        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 634880, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 310          |\n",
      "|    time_elapsed         | 12406        |\n",
      "|    total_timesteps      | 634880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076245805 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 3090         |\n",
      "|    policy_gradient_loss | -0.0207      |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 636928, Avg Reward: -0.0194, Max Reward: -0.0194\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 12466       |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011141786 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -5.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.157      |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 638976, Avg Reward: -0.0007, Max Reward: -0.0007\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 12521        |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024586087 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0332      |\n",
      "|    n_updates            | 3110         |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 641024, Avg Reward: 0.0068, Max Reward: 0.0068\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 313          |\n",
      "|    time_elapsed         | 12534        |\n",
      "|    total_timesteps      | 641024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012788123 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.632        |\n",
      "|    n_updates            | 3120         |\n",
      "|    policy_gradient_loss | -0.00957     |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 643072, Avg Reward: 0.0425, Max Reward: 0.0425\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 12561        |\n",
      "|    total_timesteps      | 643072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022682336 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 3130         |\n",
      "|    policy_gradient_loss | -0.000787    |\n",
      "|    value_loss           | 1.69         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 645120, Avg Reward: 0.0017, Max Reward: 0.0017\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 12599       |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008387821 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.617      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 647168, Avg Reward: 0.0191, Max Reward: 0.0191\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 12649        |\n",
      "|    total_timesteps      | 647168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067454563 |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 3150         |\n",
      "|    policy_gradient_loss | -0.0214      |\n",
      "|    value_loss           | 10.6         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 649216, Avg Reward: 0.0026, Max Reward: 0.0026\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 12711       |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009082368 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.214      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.529       |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.986       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 651264, Avg Reward: -0.0007, Max Reward: -0.0007\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 318          |\n",
      "|    time_elapsed         | 12761        |\n",
      "|    total_timesteps      | 651264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030147787 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -2.54        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0817      |\n",
      "|    n_updates            | 3170         |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    value_loss           | 0.734        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 653312, Avg Reward: 0.0792, Max Reward: 0.0792\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 319          |\n",
      "|    time_elapsed         | 12775        |\n",
      "|    total_timesteps      | 653312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020858904 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.414       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.466        |\n",
      "|    n_updates            | 3180         |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 655360, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 12802       |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005231618 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.869      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.89        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 657408, Avg Reward: 0.0012, Max Reward: 0.0012\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 12842       |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006261389 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.0144     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.605       |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 2.51        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 659456, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 12891        |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065271147 |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.00216      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.41         |\n",
      "|    n_updates            | 3210         |\n",
      "|    policy_gradient_loss | -0.0198      |\n",
      "|    value_loss           | 10.8         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 661504, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 12953       |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007316629 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.661       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 663552, Avg Reward: -0.0068, Max Reward: -0.0068\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 324          |\n",
      "|    time_elapsed         | 12993        |\n",
      "|    total_timesteps      | 663552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058146203 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0351       |\n",
      "|    n_updates            | 3230         |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 665600, Avg Reward: 0.0263, Max Reward: 0.0263\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 325          |\n",
      "|    time_elapsed         | 13010        |\n",
      "|    total_timesteps      | 665600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006372754 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 3240         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 2.22         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 667648, Avg Reward: -0.0874, Max Reward: -0.0874\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 13037        |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022107223 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0963       |\n",
      "|    n_updates            | 3250         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 669696, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 13076       |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009720508 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.598       |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 3.55        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 671744, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 328          |\n",
      "|    time_elapsed         | 13127        |\n",
      "|    total_timesteps      | 671744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073917075 |\n",
      "|    clip_fraction        | 0.0689       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.54         |\n",
      "|    n_updates            | 3270         |\n",
      "|    policy_gradient_loss | -0.0219      |\n",
      "|    value_loss           | 6.8          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 673792, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 13189        |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038925572 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0895      |\n",
      "|    n_updates            | 3280         |\n",
      "|    policy_gradient_loss | -0.00865     |\n",
      "|    value_loss           | 0.664        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 675840, Avg Reward: -0.0010, Max Reward: -0.0010\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 13222       |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004406201 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0769     |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | 0.00123     |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 677888, Avg Reward: 0.0089, Max Reward: 0.0089\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 13241        |\n",
      "|    total_timesteps      | 677888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027015072 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -1.01        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0627       |\n",
      "|    n_updates            | 3300         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 679936, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 13271        |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036896933 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.731       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.16         |\n",
      "|    n_updates            | 3310         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    value_loss           | 0.809        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 681984, Avg Reward: -0.0396, Max Reward: -0.0396\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 13312       |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007838758 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.0361     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 684032, Avg Reward: 0.0083, Max Reward: 0.0083\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 13367       |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004430252 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.671      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.516       |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 8.58        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 686080, Avg Reward: -0.0030, Max Reward: -0.0030\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 13431        |\n",
      "|    total_timesteps      | 686080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009135802 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 3340         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 688128, Avg Reward: 0.0154, Max Reward: 0.0154\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 336           |\n",
      "|    time_elapsed         | 13458         |\n",
      "|    total_timesteps      | 688128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087480067 |\n",
      "|    clip_fraction        | 0.0164        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.615         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.136        |\n",
      "|    n_updates            | 3350          |\n",
      "|    policy_gradient_loss | -0.000171     |\n",
      "|    value_loss           | 2.11          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 690176, Avg Reward: 0.0083, Max Reward: 0.0083\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 337          |\n",
      "|    time_elapsed         | 13479        |\n",
      "|    total_timesteps      | 690176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014685625 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0778      |\n",
      "|    n_updates            | 3360         |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 1.65         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 692224, Avg Reward: -0.0359, Max Reward: -0.0359\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 13510        |\n",
      "|    total_timesteps      | 692224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069165397 |\n",
      "|    clip_fraction        | 0.0831       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -1.73        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0331      |\n",
      "|    n_updates            | 3370         |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 0.285        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 694272, Avg Reward: 0.0034, Max Reward: 0.0034\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 13553       |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006589966 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.0884     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.867       |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 6.52        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 696320, Avg Reward: -0.0477, Max Reward: -0.0477\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 340          |\n",
      "|    time_elapsed         | 13608        |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049941535 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 3390         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    value_loss           | 2            |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 698368, Avg Reward: 0.0020, Max Reward: 0.0020\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 341          |\n",
      "|    time_elapsed         | 13675        |\n",
      "|    total_timesteps      | 698368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012926845 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0512      |\n",
      "|    n_updates            | 3400         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 0.572        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 700416, Avg Reward: 0.0078, Max Reward: 0.0078\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 13697       |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.59156e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.803       |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.000351   |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 702464, Avg Reward: -0.0237, Max Reward: -0.0237\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 343          |\n",
      "|    time_elapsed         | 13719        |\n",
      "|    total_timesteps      | 702464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010270393 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.199        |\n",
      "|    n_updates            | 3420         |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 704512, Avg Reward: -0.1999, Max Reward: -0.1999\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 13752       |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004965093 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.185      |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 706560, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 13797        |\n",
      "|    total_timesteps      | 706560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069339513 |\n",
      "|    clip_fraction        | 0.0468       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 708608, Avg Reward: 0.0027, Max Reward: 0.0027\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 13853       |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002913604 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.361      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.865       |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 710656, Avg Reward: -0.0089, Max Reward: -0.0089\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 347          |\n",
      "|    time_elapsed         | 13920        |\n",
      "|    total_timesteps      | 710656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034103463 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00333     |\n",
      "|    n_updates            | 3460         |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    value_loss           | 0.915        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 712704, Avg Reward: 0.0038, Max Reward: 0.0038\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 348           |\n",
      "|    time_elapsed         | 13935         |\n",
      "|    total_timesteps      | 712704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035841033 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.544         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.309         |\n",
      "|    n_updates            | 3470          |\n",
      "|    policy_gradient_loss | -0.000493     |\n",
      "|    value_loss           | 0.596         |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 714752, Avg Reward: 0.0701, Max Reward: 0.0701\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 349           |\n",
      "|    time_elapsed         | 13958         |\n",
      "|    total_timesteps      | 714752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063971314 |\n",
      "|    clip_fraction        | 0.00503       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.603        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.57          |\n",
      "|    n_updates            | 3480          |\n",
      "|    policy_gradient_loss | -0.00745      |\n",
      "|    value_loss           | 2.46          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 716800, Avg Reward: 0.0361, Max Reward: 0.0361\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 13991       |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004192855 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.924      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.177      |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 718848, Avg Reward: 0.0046, Max Reward: 0.0046\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 14036        |\n",
      "|    total_timesteps      | 718848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050839838 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.59         |\n",
      "|    n_updates            | 3500         |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    value_loss           | 65.3         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 720896, Avg Reward: 0.0015, Max Reward: 0.0015\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 14094       |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002159004 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.501       |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 2.93        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 722944, Avg Reward: 0.0041, Max Reward: 0.0041\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 14160       |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002918522 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -1.13       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    value_loss           | 0.69        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 724992, Avg Reward: 0.0010, Max Reward: 0.0010\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 14173        |\n",
      "|    total_timesteps      | 724992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013049152 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.831        |\n",
      "|    n_updates            | 3530         |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 1.94         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 727040, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 14197        |\n",
      "|    total_timesteps      | 727040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015158373 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.987       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.96         |\n",
      "|    n_updates            | 3540         |\n",
      "|    policy_gradient_loss | -0.00875     |\n",
      "|    value_loss           | 7.16         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 729088, Avg Reward: 0.0200, Max Reward: 0.0200\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 356          |\n",
      "|    time_elapsed         | 14231        |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064978474 |\n",
      "|    clip_fraction        | 0.0808       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.0812      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 3550         |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    value_loss           | 0.693        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 731136, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 14280       |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006658543 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0244      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.91        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 733184, Avg Reward: -0.0077, Max Reward: -0.0077\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 14339       |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009761024 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.234      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0797      |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.967       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 735232, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 14397       |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008330537 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0777     |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 2.41        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 737280, Avg Reward: -0.0070, Max Reward: -0.0070\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 14410        |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018569943 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.457       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23         |\n",
      "|    n_updates            | 3590         |\n",
      "|    policy_gradient_loss | -0.00902     |\n",
      "|    value_loss           | 6.84         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 739328, Avg Reward: -0.0337, Max Reward: -0.0337\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 14436        |\n",
      "|    total_timesteps      | 739328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058355555 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.381       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.112       |\n",
      "|    n_updates            | 3600         |\n",
      "|    policy_gradient_loss | 0.000673     |\n",
      "|    value_loss           | 2.37         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 741376, Avg Reward: -0.0405, Max Reward: -0.0405\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 14474       |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010092621 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.00178    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2           |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 5.45        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 743424, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 14523        |\n",
      "|    total_timesteps      | 743424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074437177 |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.704       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.27         |\n",
      "|    n_updates            | 3620         |\n",
      "|    policy_gradient_loss | -0.0183      |\n",
      "|    value_loss           | 62.9         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 745472, Avg Reward: -0.0012, Max Reward: -0.0012\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 364          |\n",
      "|    time_elapsed         | 14585        |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053375335 |\n",
      "|    clip_fraction        | 0.077        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.124       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.174       |\n",
      "|    n_updates            | 3630         |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 0.515        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 747520, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 14638       |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011328943 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.61        |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 749568, Avg Reward: 0.0078, Max Reward: 0.0078\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 14654        |\n",
      "|    total_timesteps      | 749568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015440108 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.81         |\n",
      "|    n_updates            | 3650         |\n",
      "|    policy_gradient_loss | -0.0076      |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 751616, Avg Reward: 0.0487, Max Reward: 0.0487\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 367          |\n",
      "|    time_elapsed         | 14681        |\n",
      "|    total_timesteps      | 751616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010449754 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.771        |\n",
      "|    n_updates            | 3660         |\n",
      "|    policy_gradient_loss | 0.000138     |\n",
      "|    value_loss           | 3.9          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 753664, Avg Reward: -0.0107, Max Reward: -0.0107\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 14719       |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008518584 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 755712, Avg Reward: -0.0747, Max Reward: -0.0747\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 14770       |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008989397 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.342      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.747       |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 757760, Avg Reward: 0.0025, Max Reward: 0.0025\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 14833       |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003848216 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.227       |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 759808, Avg Reward: -0.0233, Max Reward: -0.0233\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 14878        |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065812324 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 3700         |\n",
      "|    policy_gradient_loss | 0.0011       |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 761856, Avg Reward: -0.0040, Max Reward: -0.0040\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 372           |\n",
      "|    time_elapsed         | 14895         |\n",
      "|    total_timesteps      | 761856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037820925 |\n",
      "|    clip_fraction        | 0.00288       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.902         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.52          |\n",
      "|    n_updates            | 3710          |\n",
      "|    policy_gradient_loss | -0.00315      |\n",
      "|    value_loss           | 3.9           |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 763904, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 373          |\n",
      "|    time_elapsed         | 14923        |\n",
      "|    total_timesteps      | 763904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017361781 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.226        |\n",
      "|    n_updates            | 3720         |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 0.772        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 765952, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 14962       |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009711428 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 768000, Avg Reward: 0.0009, Max Reward: 0.0009\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 15013       |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008977731 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94        |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 8.38        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 770048, Avg Reward: -0.0024, Max Reward: -0.0024\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 376          |\n",
      "|    time_elapsed         | 15077        |\n",
      "|    total_timesteps      | 770048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028091385 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0211       |\n",
      "|    n_updates            | 3750         |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 0.892        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 772096, Avg Reward: -0.0030, Max Reward: -0.0030\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 377           |\n",
      "|    time_elapsed         | 15116         |\n",
      "|    total_timesteps      | 772096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016925758 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.801         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.44          |\n",
      "|    n_updates            | 3760          |\n",
      "|    policy_gradient_loss | -0.000569     |\n",
      "|    value_loss           | 1.63          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 774144, Avg Reward: -0.0873, Max Reward: -0.0873\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 15134        |\n",
      "|    total_timesteps      | 774144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005274572 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.5          |\n",
      "|    n_updates            | 3770         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 3.99         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 776192, Avg Reward: -0.0737, Max Reward: -0.0737\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 379           |\n",
      "|    time_elapsed         | 15164         |\n",
      "|    total_timesteps      | 776192        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079784816 |\n",
      "|    clip_fraction        | 0.00371       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.93          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.997         |\n",
      "|    n_updates            | 3780          |\n",
      "|    policy_gradient_loss | -0.00395      |\n",
      "|    value_loss           | 2.43          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 778240, Avg Reward: -0.0018, Max Reward: -0.0018\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 15207       |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009740324 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.0939      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 780288, Avg Reward: -0.0043, Max Reward: -0.0043\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 381          |\n",
      "|    time_elapsed         | 15261        |\n",
      "|    total_timesteps      | 780288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049350476 |\n",
      "|    clip_fraction        | 0.0435       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 3800         |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 782336, Avg Reward: -0.0015, Max Reward: -0.0015\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 15326        |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024498682 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 3810         |\n",
      "|    policy_gradient_loss | -0.00723     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 784384, Avg Reward: -0.0059, Max Reward: -0.0059\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 383           |\n",
      "|    time_elapsed         | 15358         |\n",
      "|    total_timesteps      | 784384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010526177 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.651         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.135        |\n",
      "|    n_updates            | 3820          |\n",
      "|    policy_gradient_loss | -0.00054      |\n",
      "|    value_loss           | 1.64          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 786432, Avg Reward: 0.0010, Max Reward: 0.0010\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 15379       |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001114511 |\n",
      "|    clip_fraction        | 0.0085      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.0335     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 788480, Avg Reward: -0.0956, Max Reward: -0.0956\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 15410        |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042282734 |\n",
      "|    clip_fraction        | 0.0645       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.931        |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 0.72         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 790528, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 15452       |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006012042 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 792576, Avg Reward: -0.0275, Max Reward: -0.0275\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 15507        |\n",
      "|    total_timesteps      | 792576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056357183 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 3860         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    value_loss           | 10.8         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 794624, Avg Reward: 0.0070, Max Reward: 0.0070\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 388          |\n",
      "|    time_elapsed         | 15572        |\n",
      "|    total_timesteps      | 794624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022531736 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.148       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 3870         |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.14         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 796672, Avg Reward: 0.0000, Max Reward: -0.0000\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 389           |\n",
      "|    time_elapsed         | 15597         |\n",
      "|    total_timesteps      | 796672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0567767e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.388         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.15          |\n",
      "|    n_updates            | 3880          |\n",
      "|    policy_gradient_loss | -7.22e-05     |\n",
      "|    value_loss           | 2.72          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 798720, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 15618       |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001056201 |\n",
      "|    clip_fraction        | 0.00732     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 800768, Avg Reward: -0.0316, Max Reward: -0.0316\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 391          |\n",
      "|    time_elapsed         | 15650        |\n",
      "|    total_timesteps      | 800768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039392873 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.331       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.211       |\n",
      "|    n_updates            | 3900         |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 0.175        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 802816, Avg Reward: -0.0194, Max Reward: -0.0194\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 15694       |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007083116 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.67        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 804864, Avg Reward: 0.0012, Max Reward: 0.0012\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 15750       |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008035529 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.554       |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 806912, Avg Reward: -0.0129, Max Reward: -0.0129\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 394          |\n",
      "|    time_elapsed         | 15816        |\n",
      "|    total_timesteps      | 806912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052156597 |\n",
      "|    clip_fraction        | 0.0876       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.175        |\n",
      "|    n_updates            | 3930         |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 808960, Avg Reward: 0.0161, Max Reward: 0.0161\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 395          |\n",
      "|    time_elapsed         | 15836        |\n",
      "|    total_timesteps      | 808960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009342071 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.257        |\n",
      "|    n_updates            | 3940         |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 2.7          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 811008, Avg Reward: 0.0250, Max Reward: 0.0250\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 396          |\n",
      "|    time_elapsed         | 15857        |\n",
      "|    total_timesteps      | 811008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010060526 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.0456       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.387        |\n",
      "|    n_updates            | 3950         |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 813056, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 397          |\n",
      "|    time_elapsed         | 15891        |\n",
      "|    total_timesteps      | 813056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065792613 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.448        |\n",
      "|    n_updates            | 3960         |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 0.768        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 815104, Avg Reward: -0.0470, Max Reward: -0.0470\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 15935       |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008160645 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 6.97        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 817152, Avg Reward: 0.0014, Max Reward: 0.0014\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 15991       |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008863473 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.74        |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 819200, Avg Reward: -0.0084, Max Reward: -0.0084\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 16059        |\n",
      "|    total_timesteps      | 819200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009966643 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.42         |\n",
      "|    n_updates            | 3990         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 3.07         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 821248, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 401          |\n",
      "|    time_elapsed         | 16071        |\n",
      "|    total_timesteps      | 821248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012042525 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72         |\n",
      "|    n_updates            | 4000         |\n",
      "|    policy_gradient_loss | -0.000501    |\n",
      "|    value_loss           | 5.71         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 823296, Avg Reward: 0.1251, Max Reward: 0.1251\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 402          |\n",
      "|    time_elapsed         | 16094        |\n",
      "|    total_timesteps      | 823296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011594417 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.277        |\n",
      "|    n_updates            | 4010         |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 825344, Avg Reward: 0.0750, Max Reward: 0.0750\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 403          |\n",
      "|    time_elapsed         | 16129        |\n",
      "|    total_timesteps      | 825344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055675814 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0174      |\n",
      "|    n_updates            | 4020         |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 827392, Avg Reward: -0.1117, Max Reward: -0.1117\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 404        |\n",
      "|    time_elapsed         | 16175      |\n",
      "|    total_timesteps      | 827392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00802695 |\n",
      "|    clip_fraction        | 0.0656     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.78       |\n",
      "|    n_updates            | 4030       |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    value_loss           | 77.7       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 829440, Avg Reward: 0.0018, Max Reward: 0.0018\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 16233       |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004491542 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38        |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 4.96        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 831488, Avg Reward: 0.0023, Max Reward: 0.0023\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 406          |\n",
      "|    time_elapsed         | 16294        |\n",
      "|    total_timesteps      | 831488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013208971 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 4050         |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    value_loss           | 3.84         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 833536, Avg Reward: 0.0015, Max Reward: 0.0015\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 407          |\n",
      "|    time_elapsed         | 16306        |\n",
      "|    total_timesteps      | 833536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010826845 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.03         |\n",
      "|    n_updates            | 4060         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 9.23         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 835584, Avg Reward: -0.0203, Max Reward: -0.0203\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 16332        |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.717452e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0658      |\n",
      "|    n_updates            | 4070         |\n",
      "|    policy_gradient_loss | -0.000189    |\n",
      "|    value_loss           | 0.923        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 837632, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 16368      |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00890892 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -0.678     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.057     |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    value_loss           | 0.49       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 839680, Avg Reward: 0.0285, Max Reward: 0.0285\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 410          |\n",
      "|    time_elapsed         | 16418        |\n",
      "|    total_timesteps      | 839680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044267513 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.9          |\n",
      "|    n_updates            | 4090         |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 841728, Avg Reward: -0.0074, Max Reward: -0.0074\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 16478       |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002650957 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -1.49       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.353       |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 843776, Avg Reward: -0.0040, Max Reward: -0.0040\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 16535       |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001588678 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    value_loss           | 4.15        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 845824, Avg Reward: -0.0082, Max Reward: -0.0082\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 413           |\n",
      "|    time_elapsed         | 16550         |\n",
      "|    total_timesteps      | 845824        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049077545 |\n",
      "|    clip_fraction        | 0.00181       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.943         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.19          |\n",
      "|    n_updates            | 4120          |\n",
      "|    policy_gradient_loss | -0.00296      |\n",
      "|    value_loss           | 5.72          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 847872, Avg Reward: -0.0156, Max Reward: -0.0156\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 414          |\n",
      "|    time_elapsed         | 16577        |\n",
      "|    total_timesteps      | 847872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.277621e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.1          |\n",
      "|    n_updates            | 4130         |\n",
      "|    policy_gradient_loss | -0.000721    |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 849920, Avg Reward: 0.0035, Max Reward: 0.0035\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 16616       |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006552395 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 851968, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 416          |\n",
      "|    time_elapsed         | 16668        |\n",
      "|    total_timesteps      | 851968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065223686 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -1.31        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 57.6         |\n",
      "|    n_updates            | 4150         |\n",
      "|    policy_gradient_loss | -0.00942     |\n",
      "|    value_loss           | 659          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 854016, Avg Reward: -0.0024, Max Reward: -0.0024\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 16731        |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050474536 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0882       |\n",
      "|    n_updates            | 4160         |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    value_loss           | 1.77         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 856064, Avg Reward: -0.0015, Max Reward: -0.0015\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 418          |\n",
      "|    time_elapsed         | 16781        |\n",
      "|    total_timesteps      | 856064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025560886 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 4170         |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 5.79         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 858112, Avg Reward: -0.0121, Max Reward: -0.0121\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 419           |\n",
      "|    time_elapsed         | 16797         |\n",
      "|    total_timesteps      | 858112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063437654 |\n",
      "|    clip_fraction        | 0.00498       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.666         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.2           |\n",
      "|    n_updates            | 4180          |\n",
      "|    policy_gradient_loss | -0.00496      |\n",
      "|    value_loss           | 7.38          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 860160, Avg Reward: -0.1212, Max Reward: -0.1212\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 420          |\n",
      "|    time_elapsed         | 16825        |\n",
      "|    total_timesteps      | 860160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015424631 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 4190         |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 0.827        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 862208, Avg Reward: 0.0279, Max Reward: 0.0279\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 421          |\n",
      "|    time_elapsed         | 16866        |\n",
      "|    total_timesteps      | 862208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073443884 |\n",
      "|    clip_fraction        | 0.0658       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.235       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.224        |\n",
      "|    n_updates            | 4200         |\n",
      "|    policy_gradient_loss | -0.0284      |\n",
      "|    value_loss           | 2.21         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 864256, Avg Reward: 0.0465, Max Reward: 0.0465\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 16918       |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008253115 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -1.26       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.56        |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 866304, Avg Reward: 0.0057, Max Reward: 0.0057\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 423          |\n",
      "|    time_elapsed         | 16982        |\n",
      "|    total_timesteps      | 866304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017168124 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 4220         |\n",
      "|    policy_gradient_loss | -0.0076      |\n",
      "|    value_loss           | 2.98         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 868352, Avg Reward: -0.0054, Max Reward: -0.0054\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 424        |\n",
      "|    time_elapsed         | 17025      |\n",
      "|    total_timesteps      | 868352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00454234 |\n",
      "|    clip_fraction        | 0.021      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.862      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.22       |\n",
      "|    n_updates            | 4230       |\n",
      "|    policy_gradient_loss | -0.000647  |\n",
      "|    value_loss           | 3.85       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 870400, Avg Reward: 0.0198, Max Reward: 0.0198\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 425           |\n",
      "|    time_elapsed         | 17042         |\n",
      "|    total_timesteps      | 870400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050714385 |\n",
      "|    clip_fraction        | 0.00771       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.677         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.45          |\n",
      "|    n_updates            | 4240          |\n",
      "|    policy_gradient_loss | -0.0078       |\n",
      "|    value_loss           | 3.73          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 872448, Avg Reward: -0.0106, Max Reward: -0.0106\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 426           |\n",
      "|    time_elapsed         | 17071         |\n",
      "|    total_timesteps      | 872448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030183556 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.939         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.44          |\n",
      "|    n_updates            | 4250          |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    value_loss           | 3.06          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 874496, Avg Reward: -0.0617, Max Reward: -0.0617\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 17112       |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007968026 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 876544, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 17164       |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007889296 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.163      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.545       |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 878592, Avg Reward: 0.0225, Max Reward: 0.0225\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 17228       |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005103969 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.792      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.426       |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 880640, Avg Reward: -0.0026, Max Reward: -0.0026\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 430           |\n",
      "|    time_elapsed         | 17262         |\n",
      "|    total_timesteps      | 880640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051395653 |\n",
      "|    clip_fraction        | 0.00244       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.0429        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.168        |\n",
      "|    n_updates            | 4290          |\n",
      "|    policy_gradient_loss | -0.00228      |\n",
      "|    value_loss           | 0.967         |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 882688, Avg Reward: 0.0053, Max Reward: 0.0053\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 17282        |\n",
      "|    total_timesteps      | 882688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011196007 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 4300         |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 884736, Avg Reward: 0.0851, Max Reward: 0.0851\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 432           |\n",
      "|    time_elapsed         | 17313         |\n",
      "|    total_timesteps      | 884736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027848117 |\n",
      "|    clip_fraction        | 0.00122       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.86          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0883       |\n",
      "|    n_updates            | 4310          |\n",
      "|    policy_gradient_loss | -0.00246      |\n",
      "|    value_loss           | 0.442         |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 886784, Avg Reward: -0.0519, Max Reward: -0.0519\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 433          |\n",
      "|    time_elapsed         | 17354        |\n",
      "|    total_timesteps      | 886784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064502475 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 4320         |\n",
      "|    policy_gradient_loss | -0.0198      |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 888832, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 434          |\n",
      "|    time_elapsed         | 17408        |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063341553 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.109       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0262       |\n",
      "|    n_updates            | 4330         |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    value_loss           | 3.38         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 890880, Avg Reward: 0.0064, Max Reward: 0.0064\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 435          |\n",
      "|    time_elapsed         | 17474        |\n",
      "|    total_timesteps      | 890880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043307445 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 4340         |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 892928, Avg Reward: -0.0069, Max Reward: -0.0069\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 436           |\n",
      "|    time_elapsed         | 17502         |\n",
      "|    total_timesteps      | 892928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047376283 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.643         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.72          |\n",
      "|    n_updates            | 4350          |\n",
      "|    policy_gradient_loss | -0.000356     |\n",
      "|    value_loss           | 5.48          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 894976, Avg Reward: 0.0237, Max Reward: 0.0237\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 437          |\n",
      "|    time_elapsed         | 17522        |\n",
      "|    total_timesteps      | 894976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024519877 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0783       |\n",
      "|    n_updates            | 4360         |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 897024, Avg Reward: -0.0181, Max Reward: -0.0181\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 438          |\n",
      "|    time_elapsed         | 17553        |\n",
      "|    total_timesteps      | 897024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015074047 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 4370         |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 0.429        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 899072, Avg Reward: -0.0020, Max Reward: -0.0020\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 17597       |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008949922 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.575       |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 7.84        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 901120, Avg Reward: 0.0038, Max Reward: 0.0038\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 17652       |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008767533 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.291      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.445       |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 903168, Avg Reward: 0.0071, Max Reward: 0.0071\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 17720        |\n",
      "|    total_timesteps      | 903168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017643329 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.695       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0717       |\n",
      "|    n_updates            | 4400         |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    value_loss           | 0.844        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 905216, Avg Reward: 0.0214, Max Reward: 0.0214\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 442           |\n",
      "|    time_elapsed         | 17743         |\n",
      "|    total_timesteps      | 905216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9777213e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.368        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.09          |\n",
      "|    n_updates            | 4410          |\n",
      "|    policy_gradient_loss | -6.65e-05     |\n",
      "|    value_loss           | 2.23          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 907264, Avg Reward: -0.0006, Max Reward: -0.0006\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 443           |\n",
      "|    time_elapsed         | 17764         |\n",
      "|    total_timesteps      | 907264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077791966 |\n",
      "|    clip_fraction        | 0.00513       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.774         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.424         |\n",
      "|    n_updates            | 4420          |\n",
      "|    policy_gradient_loss | -0.0064       |\n",
      "|    value_loss           | 1.25          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 909312, Avg Reward: -0.1006, Max Reward: -0.1006\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 17798       |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002249265 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0964     |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 911360, Avg Reward: -0.0013, Max Reward: -0.0013\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 17843       |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007989657 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 913408, Avg Reward: -0.0182, Max Reward: -0.0182\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 17899       |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005307734 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.474       |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 915456, Avg Reward: 0.0100, Max Reward: 0.0100\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 447          |\n",
      "|    time_elapsed         | 17967        |\n",
      "|    total_timesteps      | 915456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007935427 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.139       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.042        |\n",
      "|    n_updates            | 4460         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 917504, Avg Reward: 0.0002, Max Reward: 0.0002\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 448           |\n",
      "|    time_elapsed         | 17983         |\n",
      "|    total_timesteps      | 917504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025397175 |\n",
      "|    clip_fraction        | 0.00449       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.474         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0366        |\n",
      "|    n_updates            | 4470          |\n",
      "|    policy_gradient_loss | -0.000608     |\n",
      "|    value_loss           | 2.48          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 919552, Avg Reward: 0.0109, Max Reward: 0.0109\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 18006        |\n",
      "|    total_timesteps      | 919552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006831431 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00163      |\n",
      "|    n_updates            | 4480         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.52         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 921600, Avg Reward: 0.0148, Max Reward: 0.0148\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 450          |\n",
      "|    time_elapsed         | 18042        |\n",
      "|    total_timesteps      | 921600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039193267 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.161       |\n",
      "|    n_updates            | 4490         |\n",
      "|    policy_gradient_loss | -0.00773     |\n",
      "|    value_loss           | 0.405        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 923648, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 18089       |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013794526 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.227      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 925696, Avg Reward: 0.0068, Max Reward: 0.0068\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 18149       |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003631264 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.11       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.735       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 927744, Avg Reward: -0.0163, Max Reward: -0.0163\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 18218        |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035135315 |\n",
      "|    clip_fraction        | 0.0358       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.118       |\n",
      "|    n_updates            | 4520         |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 929792, Avg Reward: 0.0018, Max Reward: 0.0018\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 454           |\n",
      "|    time_elapsed         | 18230         |\n",
      "|    total_timesteps      | 929792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050805975 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.615         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.02          |\n",
      "|    n_updates            | 4530          |\n",
      "|    policy_gradient_loss | 2.1e-05       |\n",
      "|    value_loss           | 2.12          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 931840, Avg Reward: 0.0200, Max Reward: 0.0200\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 455          |\n",
      "|    time_elapsed         | 18255        |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032354572 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.136       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.306        |\n",
      "|    n_updates            | 4540         |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 933888, Avg Reward: 0.0073, Max Reward: 0.0073\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 18291       |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006364504 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.239      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.234       |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.686       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 935936, Avg Reward: -0.0094, Max Reward: -0.0094\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 18340       |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009003485 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.766       |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 937984, Avg Reward: -0.0004, Max Reward: -0.0004\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 18401       |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005230042 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.277      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 940032, Avg Reward: -0.0017, Max Reward: -0.0017\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 459           |\n",
      "|    time_elapsed         | 18461         |\n",
      "|    total_timesteps      | 940032        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050413236 |\n",
      "|    clip_fraction        | 0.00122       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.699         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.01          |\n",
      "|    n_updates            | 4580          |\n",
      "|    policy_gradient_loss | -0.00273      |\n",
      "|    value_loss           | 5.05          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 942080, Avg Reward: 0.0086, Max Reward: 0.0086\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 460           |\n",
      "|    time_elapsed         | 18475         |\n",
      "|    total_timesteps      | 942080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019772255 |\n",
      "|    clip_fraction        | 0.00259       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.899         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.46          |\n",
      "|    n_updates            | 4590          |\n",
      "|    policy_gradient_loss | -0.00276      |\n",
      "|    value_loss           | 3.52          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 944128, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 461           |\n",
      "|    time_elapsed         | 18501         |\n",
      "|    total_timesteps      | 944128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032126578 |\n",
      "|    clip_fraction        | 0.00176       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.644         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.178        |\n",
      "|    n_updates            | 4600          |\n",
      "|    policy_gradient_loss | -0.000772     |\n",
      "|    value_loss           | 0.406         |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 946176, Avg Reward: -0.0553, Max Reward: -0.0553\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 18539       |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010083804 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.0897     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.143      |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.344       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 948224, Avg Reward: -0.0555, Max Reward: -0.0555\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 18590       |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008125257 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 9.89        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 950272, Avg Reward: 0.0044, Max Reward: 0.0044\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 464          |\n",
      "|    time_elapsed         | 18651        |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051085856 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.158       |\n",
      "|    n_updates            | 4630         |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 952320, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 465          |\n",
      "|    time_elapsed         | 18705        |\n",
      "|    total_timesteps      | 952320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020372546 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0414       |\n",
      "|    n_updates            | 4640         |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    value_loss           | 0.742        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 954368, Avg Reward: 0.0000, Max Reward: -0.0000\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 466           |\n",
      "|    time_elapsed         | 18722         |\n",
      "|    total_timesteps      | 954368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017994968 |\n",
      "|    clip_fraction        | 0.00303       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.84          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.811         |\n",
      "|    n_updates            | 4650          |\n",
      "|    policy_gradient_loss | -0.00247      |\n",
      "|    value_loss           | 2.53          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 956416, Avg Reward: 0.1735, Max Reward: 0.1735\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 51            |\n",
      "|    iterations           | 467           |\n",
      "|    time_elapsed         | 18749         |\n",
      "|    total_timesteps      | 956416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061852694 |\n",
      "|    clip_fraction        | 0.0143        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.883         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.201        |\n",
      "|    n_updates            | 4660          |\n",
      "|    policy_gradient_loss | -0.000692     |\n",
      "|    value_loss           | 0.864         |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 958464, Avg Reward: 0.0418, Max Reward: 0.0418\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 18789       |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006327407 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.00769    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.944       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 960512, Avg Reward: 0.0579, Max Reward: 0.0579\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 469          |\n",
      "|    time_elapsed         | 18841        |\n",
      "|    total_timesteps      | 960512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055714473 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -1.09        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86         |\n",
      "|    n_updates            | 4680         |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 99.8         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 962560, Avg Reward: 0.0089, Max Reward: 0.0089\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 18904        |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023609102 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.202        |\n",
      "|    n_updates            | 4690         |\n",
      "|    policy_gradient_loss | -0.00866     |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 964608, Avg Reward: 0.0010, Max Reward: 0.0010\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 471          |\n",
      "|    time_elapsed         | 18950        |\n",
      "|    total_timesteps      | 964608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001867373 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.718        |\n",
      "|    n_updates            | 4700         |\n",
      "|    policy_gradient_loss | -0.000746    |\n",
      "|    value_loss           | 5.04         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 966656, Avg Reward: 0.0004, Max Reward: 0.0004\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 472           |\n",
      "|    time_elapsed         | 18968         |\n",
      "|    total_timesteps      | 966656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041191652 |\n",
      "|    clip_fraction        | 0.00171       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.632         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.82          |\n",
      "|    n_updates            | 4710          |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    value_loss           | 5.7           |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 968704, Avg Reward: 0.8743, Max Reward: 0.8743\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 18997        |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014171851 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.197        |\n",
      "|    n_updates            | 4720         |\n",
      "|    policy_gradient_loss | 0.00107      |\n",
      "|    value_loss           | 1.65         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 970752, Avg Reward: 0.0000, Max Reward: 0.0000\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 19038       |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005033577 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.3         |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 972800, Avg Reward: -0.0082, Max Reward: -0.0082\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 19092       |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008479513 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.92       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.63        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 974848, Avg Reward: -0.0035, Max Reward: -0.0035\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 476          |\n",
      "|    time_elapsed         | 19157        |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031123436 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.242        |\n",
      "|    n_updates            | 4750         |\n",
      "|    policy_gradient_loss | -0.00851     |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 976896, Avg Reward: -0.0078, Max Reward: -0.0078\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 477          |\n",
      "|    time_elapsed         | 19196        |\n",
      "|    total_timesteps      | 976896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007295442 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.138       |\n",
      "|    n_updates            | 4760         |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 0.766        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 978944, Avg Reward: -0.0050, Max Reward: -0.0050\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 478           |\n",
      "|    time_elapsed         | 19214         |\n",
      "|    total_timesteps      | 978944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027469173 |\n",
      "|    clip_fraction        | 0.00303       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.01          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.517         |\n",
      "|    n_updates            | 4770          |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    value_loss           | 3.29          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 980992, Avg Reward: -0.0766, Max Reward: -0.0766\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 479          |\n",
      "|    time_elapsed         | 19244        |\n",
      "|    total_timesteps      | 980992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019118062 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.181       |\n",
      "|    n_updates            | 4780         |\n",
      "|    policy_gradient_loss | -0.000236    |\n",
      "|    value_loss           | 0.769        |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 983040, Avg Reward: 0.0071, Max Reward: 0.0071\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 19286        |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072541507 |\n",
      "|    clip_fraction        | 0.0853       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.496        |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | -0.0283      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 985088, Avg Reward: -0.0181, Max Reward: -0.0181\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 19341       |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006742096 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.697       |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 987136, Avg Reward: 0.0019, Max Reward: 0.0019\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 19407        |\n",
      "|    total_timesteps      | 987136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043487474 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -1.02        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.342        |\n",
      "|    n_updates            | 4810         |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 989184, Avg Reward: 0.0049, Max Reward: 0.0049\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 483           |\n",
      "|    time_elapsed         | 19440         |\n",
      "|    total_timesteps      | 989184        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026188383 |\n",
      "|    clip_fraction        | 0.00327       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.782         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.23          |\n",
      "|    n_updates            | 4820          |\n",
      "|    policy_gradient_loss | -0.000711     |\n",
      "|    value_loss           | 4.04          |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 991232, Avg Reward: -0.0078, Max Reward: -0.0078\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 484           |\n",
      "|    time_elapsed         | 19460         |\n",
      "|    total_timesteps      | 991232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021616355 |\n",
      "|    clip_fraction        | 0.00195       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.323         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0216        |\n",
      "|    n_updates            | 4830          |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    value_loss           | 2.3           |\n",
      "-------------------------------------------\n",
      "[Callback] Rollout finished at step 993280, Avg Reward: -0.1483, Max Reward: -0.1483\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 485        |\n",
      "|    time_elapsed         | 19492      |\n",
      "|    total_timesteps      | 993280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00876561 |\n",
      "|    clip_fraction        | 0.0249     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.869      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 4840       |\n",
      "|    policy_gradient_loss | -0.000246  |\n",
      "|    value_loss           | 0.421      |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 995328, Avg Reward: -0.0632, Max Reward: -0.0632\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 486        |\n",
      "|    time_elapsed         | 19537      |\n",
      "|    total_timesteps      | 995328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00689953 |\n",
      "|    clip_fraction        | 0.067      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | -1.04      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.34       |\n",
      "|    n_updates            | 4850       |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    value_loss           | 8.31       |\n",
      "----------------------------------------\n",
      "[Callback] Rollout finished at step 997376, Avg Reward: 0.0033, Max Reward: 0.0033\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 487          |\n",
      "|    time_elapsed         | 19594        |\n",
      "|    total_timesteps      | 997376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032998845 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.000859    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.29         |\n",
      "|    n_updates            | 4860         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "[Callback] Rollout finished at step 999424, Avg Reward: -0.0161, Max Reward: -0.0161\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 19662       |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004867888 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -1.74       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.14       |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.000773   |\n",
      "|    value_loss           | 0.856       |\n",
      "-----------------------------------------\n",
      "[Callback] Rollout finished at step 1001472, Avg Reward: 0.0000, Max Reward: -0.0000\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 489          |\n",
      "|    time_elapsed         | 19688        |\n",
      "|    total_timesteps      | 1001472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.465431e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71         |\n",
      "|    n_updates            | 4880         |\n",
      "|    policy_gradient_loss | -6.93e-06    |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "[Done] Model saved for NVDA at models/ppo_NVDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "# Run PPO training using files in `data/` directory\n",
    "%run train/train_ppo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6d103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../debug_rewards.log': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! ls ../debug_rewards.log\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
